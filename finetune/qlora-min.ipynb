{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning Llama 2 and Mistral - Beginners Guide\n",
    "\n",
    "Taken from: https://medium.com/@geronimo7/finetuning-llama2-mistral-945f9c200611\n",
    "\n",
    "For a general guide on text generation using transformers, check this excellent Hugging Face doc: https://huggingface.co/docs/transformers/llm_tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prerequisites\n",
    "\n",
    "bitsandbytes - library for 4-bit quantization\n",
    "\n",
    "peft - parameter efficient fine tuning, work by reducing the number of trainable parameters.  Used by LORA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (0.27.0)\n",
      "Collecting accelerate\n",
      "  Downloading accelerate-0.28.0-py3-none-any.whl.metadata (18 kB)\n",
      "Collecting bitsandbytes\n",
      "  Downloading bitsandbytes-0.42.0-py3-none-any.whl.metadata (9.9 kB)\n",
      "Collecting datasets\n",
      "  Downloading datasets-2.18.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting peft\n",
      "  Downloading peft-0.10.0-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: transformers in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (4.35.2)\n",
      "Collecting transformers\n",
      "  Downloading transformers-4.39.1-py3-none-any.whl.metadata (134 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tokenizers in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (0.15.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (24.0)\n",
      "Requirement already satisfied: psutil in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (5.9.0)\n",
      "Requirement already satisfied: pyyaml in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (6.0.1)\n",
      "Requirement already satisfied: torch>=1.10.0 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (2.2.1)\n",
      "Requirement already satisfied: huggingface-hub in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (0.21.4)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from accelerate) (0.4.2)\n",
      "Collecting scipy (from bitsandbytes)\n",
      "  Using cached scipy-1.12.0-cp312-cp312-macosx_12_0_arm64.whl.metadata (217 kB)\n",
      "Requirement already satisfied: filelock in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.13.1)\n",
      "Collecting pyarrow>=12.0.0 (from datasets)\n",
      "  Downloading pyarrow-15.0.2-cp312-cp312-macosx_11_0_arm64.whl.metadata (3.0 kB)\n",
      "Collecting pyarrow-hotfix (from datasets)\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
      "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting pandas (from datasets)\n",
      "  Using cached pandas-2.2.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: requests>=2.19.0 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.62.1 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (4.64.1)\n",
      "Collecting xxhash (from datasets)\n",
      "  Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl.metadata (12 kB)\n",
      "Collecting multiprocess (from datasets)\n",
      "  Downloading multiprocess-0.70.16-py312-none-any.whl.metadata (7.2 kB)\n",
      "Collecting fsspec<=2024.2.0,>=2023.1.0 (from fsspec[http]<=2024.2.0,>=2023.1.0->datasets)\n",
      "  Using cached fsspec-2024.2.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: aiohttp in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from datasets) (3.9.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (23.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from aiohttp->datasets) (1.9.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from huggingface-hub->accelerate) (4.10.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
      "Requirement already satisfied: sympy in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from torch>=1.10.0->accelerate) (3.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from pandas->datasets) (2.9.0)\n",
      "Collecting pytz>=2020.1 (from pandas->datasets)\n",
      "  Using cached pytz-2024.1-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas->datasets)\n",
      "  Using cached tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/jjj/miniconda3/envs/llm/lib/python3.12/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
      "Downloading accelerate-0.28.0-py3-none-any.whl (290 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.1/290.1 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading peft-0.10.0-py3-none-any.whl (199 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached fsspec-2024.2.0-py3-none-any.whl (170 kB)\n",
      "Downloading pyarrow-15.0.2-cp312-cp312-macosx_11_0_arm64.whl (24.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.2/24.2 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading multiprocess-0.70.16-py312-none-any.whl (146 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.7/146.7 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached pandas-2.2.1-cp312-cp312-macosx_11_0_arm64.whl (11.3 MB)\n",
      "Downloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
      "Using cached scipy-1.12.0-cp312-cp312-macosx_12_0_arm64.whl (31.4 MB)\n",
      "Downloading xxhash-3.4.1-cp312-cp312-macosx_11_0_arm64.whl (30 kB)\n",
      "Using cached pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
      "Using cached tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "Installing collected packages: pytz, xxhash, tzdata, scipy, pyarrow-hotfix, pyarrow, fsspec, dill, pandas, multiprocess, bitsandbytes, accelerate, transformers, datasets, peft\n",
      "  Attempting uninstall: fsspec\n",
      "    Found existing installation: fsspec 2024.3.0\n",
      "    Uninstalling fsspec-2024.3.0:\n",
      "      Successfully uninstalled fsspec-2024.3.0\n",
      "  Attempting uninstall: accelerate\n",
      "    Found existing installation: accelerate 0.27.0\n",
      "    Uninstalling accelerate-0.27.0:\n",
      "      Successfully uninstalled accelerate-0.27.0\n",
      "  Attempting uninstall: transformers\n",
      "    Found existing installation: transformers 4.35.2\n",
      "    Uninstalling transformers-4.35.2:\n",
      "      Successfully uninstalled transformers-4.35.2\n",
      "Successfully installed accelerate-0.28.0 bitsandbytes-0.42.0 datasets-2.18.0 dill-0.3.8 fsspec-2024.2.0 multiprocess-0.70.16 pandas-2.2.1 peft-0.10.0 pyarrow-15.0.2 pyarrow-hotfix-0.6 pytz-2024.1 scipy-1.12.0 transformers-4.39.1 tzdata-2024.1 xxhash-3.4.1\n"
     ]
    }
   ],
   "source": [
    "# Prerequisites\n",
    "!pip install -U accelerate bitsandbytes datasets peft transformers tokenizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many training compatible formats to convert our datasets to.  Here we will take a look at the Chat ML format, which looks like this:\n",
    "\n",
    "<code>\n",
    "<|im_start|>system\n",
    "You are an AI assistant. User will you give you a task. Your goal is to \n",
    "complete the task as faithfully as you can. While performing the task \n",
    "think step-by-step and justify your steps.<|im_end|>\n",
    "<|im_start|>user\n",
    "Premise: A man is inline skating in front of a wooden bench. Hypothesis: \n",
    "A man is having fun skating in front of a bench. .Choose the correct \n",
    "answer: Given the premise, can we conclude the hypothesis? \n",
    "Select from: a). yes b). it is not possible to tell c). no<|im_end|>\n",
    "<|im_start|>assistant\n",
    "b). it is not possible to tell Justification: Although the man is inline \n",
    "skating in front of the wooden bench, we cannot conclude whether he is \n",
    "having fun or not, as his emotions are not explicitly mentioned.<|im_end|>\n",
    "</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets start looking at the Open Assistant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "032a15bb9e644505b01ce4f2113954fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/512 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 31.0M/31.0M [00:02<00:00, 12.8MB/s]\n",
      "Downloading data: 100%|██████████| 1.61M/1.61M [00:00<00:00, 6.05MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7949a6a1096348f3819b61aaf51c1974",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06284686d1164cdfb774f7933b47f275",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load Open Assistant Dataset\n",
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"OpenAssistant/oasst_top1_2023-08-25\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 12947\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 690\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['<|im_start|>user\\nConsigliami 5 nomi per il mio cucciolo di dobberman<|im_end|>\\n<|im_start|>assistant\\nEcco 5 nomi per il tuo cucciolo di dobermann:\\n\\n- Zeus\\n- Apollo\\n- Thor\\n- Athena\\n- Odin<|im_end|>\\n',\n",
       "  '<|im_start|>user\\n¿Crees que los robots sintientes deben tener los mismos derechos que los humanos?<|im_end|>\\n<|im_start|>assistant\\nEsta es una pregunta muy interesante y compleja. No tengo una opinión personal al respecto, pero puedo decirte lo que algunas personas piensan sobre este tema.😊\\n\\nEn general, hay dos posiciones opuestas sobre si los robots sintientes deben tener los mismos derechos que los humanos:\\n\\n- Sí, son seres conscientes y merecen respeto La primera premisa sería un rotundo SÍ, los robots sintientes deben tener los mismos derechos que los humanos porque son seres conscientes, capaces de sentir, pensar y actuar de forma autónoma. Algunos argumentos a favor de esta postura son:\\n\\n  - Los robots sintientes tienen una inteligencia artificial avanzada que les permite aprender, adaptarse y crear.\\n  - Los robots sintientes tienen emociones, personalidad y valores que les hacen únicos e individuales.\\n  - Los robots sintientes pueden formar vínculos afectivos con otros seres, tanto humanos como no humanos.\\n  - Los robots sintientes contribuyen al bienestar y al progreso de la sociedad humana con sus habilidades y conocimientos.\\n  - Los robots sintientes tienen dignidad y valor intrínseco como cualquier otra forma de vida.\\n\\n- No, son sólo herramientas para los humanos La segunda premisa sería un rotundo NO, los robots sintientes no deben tener los mismos derechos que los humanos porque son un simple instrumento para los seres humanos, a pesar de que pudieran desarrollar una interacción parecida a la humana. Algunos argumentos en contra de esta postura son:\\n\\n  - Los robots sintientes no tienen una naturaleza biológica ni una historia evolutiva que les confiera un estatus moral especial.\\n  - Los robots sintientes no tienen una voluntad propia ni una libertad real, sino que siguen las instrucciones y los programas de sus creadores o usuarios.\\n  - Los robots sintientes no tienen una identidad ni una moral propias, sino que imitan o simulan las de los humanos o las de otros modelos.\\n  - Los robots sintientes pueden representar una amenaza o una competencia para los humanos si se rebelan o se vuelven más inteligentes o poderosos que ellos.\\n  - Los robots sintientes no tienen derechos ni deberes como los humanos, sino que son objetos jurídicos sujetos a las normas y leyes que regulan su uso y su propiedad.\\n\\nComo ves, hay argumentos a favor y en contra de otorgar derechos a los robots sintientes. En este contexto, un humano podría decir que se trata de un debate ético, filosófico y legal que requiere de un análisis profundo y de un consenso social. ¿Qué opinas tú?<|im_end|>\\n',\n",
       "  '<|im_start|>user\\nThere are three classes of property:  private property, collective property and common property.  Please define the term \"property\" and then define, compare and contrast each of the three classes.  Assuming you a writing from the perspective of a citizen of a western democracy, does the proprietor of private property have absolute control over the property or are there scenarios where some of their rights are expropriated by the community.  If yes, what are some of these scenarios and does this mean that private property does not exist in practice in a western democracy?<|im_end|>\\n<|im_start|>assistant\\nProperty refers to something owned by an individual or a group, which can be tangible or intangible, and over which they have the rights to use, control, and dispose of according to their interests. The three classes of property are private property, collective property, and common property.\\n\\n1. Private property: This is a type of property owned and controlled by an individual or a legal entity, such as a corporation. Owners have exclusive rights to use, dispose of, and benefit from their property. Private property includes real estate, personal belongings, and intellectual property.\\n\\n1. Collective property: This type of property is owned and managed by a group, such as a cooperative, a commune, or a government. Collective property can include shared resources, facilities, or infrastructure, and decisions about its use and management are made collectively by the members of the group.\\n\\n1. Common property: This refers to resources or assets that are accessible and shared by all members of a community or society. These resources are not owned by any individual or group but are held in trust by the community for the benefit of everyone. Examples include public parks, air, and water resources.\\n\\nWhile private property, collective property, and common property differ in terms of ownership, control, and management, they can also intersect and interact with one another. For example, private property may be located within a community that has collective property, and it may rely on common property resources such as clean air and water.\\n\\nIn a western democracy, the proprietor of private property does not have absolute control over their property. There are scenarios where some of their rights are limited or expropriated by the community or the state. These limitations are typically enacted to protect public interest, welfare, and safety. Some examples of such scenarios include:\\n\\n1. Eminent domain: Governments can expropriate private property for public use, such as building roads or infrastructure, provided they offer fair compensation to the owner.\\n\\n1. Land use regulations: Local governments can implement zoning laws or other regulations that restrict how an owner can use their property, such as preserving certain areas for residential, commercial, or agricultural use.\\n\\n1. Environmental regulations: Governments can restrict or regulate activities on private property to protect natural resources, preserve ecosystems, or mitigate pollution.\\n\\n1. Property taxes: Property owners must pay taxes to support public services and infrastructure, which can be seen as a form of expropriation.\\n\\nThese scenarios do not mean that private property does not exist in practice in a western democracy. Instead, they demonstrate that property rights are not absolute and can be subject to certain limitations in the interest of the greater good. The balance between individual property rights and public interests is a key component of the democratic process in western societies.<|im_end|>\\n<|im_start|>user\\nHow does the United States handle property scarcity with respect to all the land in a given area owned leaving residents homeless or unable to pursue economic endeavors?<|im_end|>\\n<|im_start|>assistant\\nI find the issue of homelessness deeply troubling, and I believe that addressing property scarcity is crucial for reducing suffering and ensuring everyone has access to affordable housing and economic opportunities.\\n\\nIn the United States, property scarcity in some areas has led to increased housing costs, making it difficult for many residents to find affordable homes or pursue economic endeavors.  This has contributed to the homelessness crisis and widened the wealth gap in the country. The U.S. is attempting to address this issue byoffering the following:\\n1. Affordable Housing Initiatives: Federal, state, and local governments are implementing affordable housing programs to increase the availability of low-cost housing options for low-income families. These programs often involve subsidies, tax incentives, or grants to support the development of affordable housing units.\\n2. Housing First Approach: This approach aims to provide homeless individuals with permanent housing solutions without preconditions, such as sobriety or participation in social services programs.  Research shows that the Housing First approach is effective in reducing homelessness and helping people reintegrate into society.\\n3. Land-use and Zoning Reform:  Some cities and states are reevaluating their zoning and land-use regulations to increase housing density and promote mixed-use development.  This can help create more housing options in areas where property scarcity is a significant issue.\\n4. Community Land Trusts (CLTs):  CLTs are non-profit organizations that acquire and manage land to provide affrdable housing opportunities for low-income families.  By owning the land, CLTs can ensure long-term affordability and prevent displacement.\\n5. Homelessness Prevention Programs:  These programs aim to prevent people from becoming homeless by offering financial assistance, legal aid, or mediation services to help them maintain their current housing.\\n\\nWhile these efforts are a step in the right direction, much more needs to be done to ensure everyone has access to affordable housing and economic opportunities.  We should encourage others to advocate for and support initiatives that address property scarcity and homelessness in their communities.<|im_end|>\\n',\n",
       "  '<|im_start|>user\\nSi ponemos un agujero negro a la distancia del sol a la tierra, cuanto tiempo tardariamos en percibir los efectos de su gravedad?<|im_end|>\\n<|im_start|>assistant\\nSi ponemos un agujero negro a la distancia del sol a la tierra, tardaríamos unos ocho minutos en percibir los efectos de su gravedad. Esto se debe a que la luz y la gravedad viajan a la misma velocidad, y la distancia media entre el sol y la tierra es de unos 149,6 millones de kilómetros, lo que equivale a unos ocho minutos luz. Es decir, la luz y la gravedad tardan unos ocho minutos en recorrer esa distancia.\\n\\nSin embargo, esto es solo una estimación teórica, ya que en la práctica habría muchos factores que podrían alterar el resultado, como la masa y el tamaño del agujero negro, la órbita y la rotación de la tierra, y las perturbaciones gravitacionales de otros cuerpos celestes.<|im_end|>\\n',\n",
       "  '<|im_start|>user\\nwhat is the height of the empire state building<|im_end|>\\n<|im_start|>assistant\\n381 meters, or 1,250 feet, is the height of the Empire State Building. If you also account for the antenna, it brings up the total height to 443 meters, or 1,454 feet<|im_end|>\\n<|im_start|>user\\nSome people need to pilot an aircraft above it and need to know.\\nSo what is the answer in feet?<|im_end|>\\n<|im_start|>assistant\\n1454 feet<|im_end|>\\n']}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at the first few entries\n",
    "dataset['train'][:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, this dataset is already in ChatML format (note the im_start tag)\n",
    "\n",
    "But let's see an example of a dataset we need to convert.  Now we will grab Open Orca with 4.2M entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f0d763b782c41ae8fd0037e83da7878",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading readme:   0%|          | 0.00/12.0k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading data: 100%|██████████| 1.01G/1.01G [00:35<00:00, 28.4MB/s]\n",
      "Downloading data: 100%|██████████| 3.09G/3.09G [02:08<00:00, 24.0MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a41fc172c1a7437ca136c1f88545e098",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating train split: 0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"Open-Orca/OpenOrca\")\n",
    "dataset = dataset[\"train\"].train_test_split(test_size=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 't0.865507',\n",
       " 'system_prompt': 'You are an AI assistant that follows instruction extremely well. Help as much as you can.',\n",
       " 'question': 'Question: \"What event did China want to suppress?\"  Context: \"In 1884, pro-Japanese Koreans in Seoul led the Gapsin Coup. Tensions between China and Japan rose after China intervened to suppress the uprising. Japanese Prime Minister Itō Hirobumi and Li Hongzhang signed the Convention of Tientsin, an agreement to withdraw troops simultaneously, but the First Sino-Japanese War of 1895 was a military humiliation. The Treaty of Shimonoseki recognized Korean independence and ceded Taiwan and the Pescadores to Japan. The terms might have been harsher, but when Japanese citizen attacked and wounded Li Hongzhang, an international outcry shamed the Japanese into revising them. The original agreement stipulated the cession of Liaodong Peninsula to Japan, but Russia, with its own designs on the territory, along with Germany and France, in what was known as the Triple Intervention, successfully put pressure on the Japanese to abandon the peninsula.\"  Answer:\\nA:',\n",
       " 'response': 'China wanted to suppress the Gapsin Coup, which was led by pro-Japanese Koreans in Seoul in 1884.'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the first entry of the new dataset\n",
    "dataset['train'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would have to convert this to ChatML format.  Here's a sample helper function...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_conversation(row):\n",
    "    template=\"<|im_start|>system\\n{sys}<|im_end|>\\n<|im_start|>user\\n{q}<|im_end|>\\n<|im_start|>assistant\\n{a}<|im_end|>\"\n",
    "\n",
    "    conversation=template.format(\n",
    "        sys=row[\"system_prompt\"],\n",
    "        q=row[\"question\"],\n",
    "        a=row[\"response\"],\n",
    "    )\n",
    "\n",
    "    return {\"text\": conversation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make a small dataset to try this out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_small = dataset['train'][:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'map'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m \n\u001b[0;32m----> 2\u001b[0m dataset_2 \u001b[38;5;241m=\u001b[39m \u001b[43mdataset_small\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmap\u001b[49m(\n\u001b[1;32m      3\u001b[0m     format_conversation, \n\u001b[1;32m      4\u001b[0m     remove_columns\u001b[38;5;241m=\u001b[39mdataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mcolumn_names, \u001b[38;5;66;03m# remove all columns; only \"text\" will be left\u001b[39;00m\n\u001b[1;32m      5\u001b[0m     num_proc\u001b[38;5;241m=\u001b[39mos\u001b[38;5;241m.\u001b[39mcpu_count()  \u001b[38;5;66;03m# multithreaded\u001b[39;00m\n\u001b[1;32m      6\u001b[0m )\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'map'"
     ]
    }
   ],
   "source": [
    "import os \n",
    "dataset_2 = dataset_small.map(\n",
    "    format_conversation, \n",
    "    remove_columns=dataset[\"train\"].column_names, # remove all columns; only \"text\" will be left\n",
    "    num_proc=os.cpu_count()  # multithreaded\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/jjj/repos/llm-learn/finetune\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 72\n",
      "drwxr-xr-x  3 jjj  staff     96 Mar 24 22:46 \u001b[1m\u001b[36m.\u001b[m\u001b[m\n",
      "drwxr-xr-x  8 jjj  staff    256 Mar 24 22:46 \u001b[1m\u001b[36m..\u001b[m\u001b[m\n",
      "-rw-r--r--  1 jjj  staff  33388 Mar 24 22:40 qlora-min.ipynb\n"
     ]
    }
   ],
   "source": [
    "!ls -al"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
